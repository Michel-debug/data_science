{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced scikit-learn\n",
    "\n",
    "Authors: [Alexandre Gramfort](http://alexandre.gramfort.net), [Thomas Moreau](https://tommoral.github.io/about.html), and [Pedro L. C. Rodrigues](https://plcrodrigues.github.io/).\n",
    "\n",
    "The aim of this notebook is:\n",
    "\n",
    "  - To explain the **full scikit-learn API** (estimators, transformers, classifiers, regressors, splitters)\n",
    "      - to explain how to assemble these objects in complex **pipelines with mixed data types** (numerical, categorical etc.) using `Pipeline` and `ColumnTransformer` objects.\n",
    "  - Have you **write your own transformer, splitter and classifier**.\n",
    "  \n",
    "## Table of contents\n",
    "\n",
    "* [1 Working only with numerical data](#workingnumerical)\n",
    "    * [1.1 Pandas preprocessing](#workingnumerical_pandas)\n",
    "    * [1.2 Making it less error prone using scikit-learn](#workingnumerical_errorprone)    \n",
    "* [2 Working only with categorical data](#workingcategorical)\n",
    "* [3 Combining both categorical and numerical data in the pipeline](#combining)\n",
    "* [4 From one split to cross-validation](#crossvalidation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explain these concepts we will start from a full working code based on the Titanic dataset. \n",
    "\n",
    "Then, we will deconstruct all the blocks and start writing our own Python classes.\n",
    "\n",
    "First, let's fetch the Titanic dataset directly from [OpenML](https://openml.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenchenjunjie/anaconda3/lib/python3.11/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  ...                        home.dest\n",
       "0     1.0  ...                     St Louis, MO\n",
       "1     1.0  ...  Montreal, PQ / Chesterville, ON\n",
       "2     1.0  ...  Montreal, PQ / Chesterville, ON\n",
       "3     1.0  ...  Montreal, PQ / Chesterville, ON\n",
       "4     1.0  ...  Montreal, PQ / Chesterville, ON\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification task is to predict whether or not a person will survive the Titanic disaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1304    0\n",
       "1305    0\n",
       "1306    0\n",
       "1307    0\n",
       "1308    0\n",
       "Name: survived, Length: 1309, dtype: category\n",
       "Categories (2, object): ['0', '1']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the data into a training and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_df, y, random_state=42\n",
    ")  #默认是0.25\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>QUESTIONS</b>:</p>\n",
    "    <ul>\n",
    "        <li>What would happen if you tried to fit a <tt>RandomForestClassifier</tt>?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Working only with numerical data <a class=\"anchor\" id=\"workingnumerical\"></a> [↑](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a model using only numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass        float64\n",
       "name           object\n",
       "sex          category\n",
       "age           float64\n",
       "sibsp         float64\n",
       "parch         float64\n",
       "ticket         object\n",
       "fare          float64\n",
       "cabin          object\n",
       "embarked     category\n",
       "boat           object\n",
       "body          float64\n",
       "home.dest      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Pandas preprocessing  <a class=\"anchor\" id=\"workingnumerical_pandas\"></a> [↑](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using scikit-learn, we will do some simple preprocessing using pandas. First, let's select only a few the numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.2458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.7792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>3.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>981 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass   age  parch      fare\n",
       "1139     3.0  38.0    0.0    7.8958\n",
       "678      3.0   6.0    1.0   15.2458\n",
       "290      1.0  52.0    1.0   79.6500\n",
       "285      1.0  67.0    0.0  221.7792\n",
       "1157     3.0  18.0    1.0   20.2125\n",
       "...      ...   ...    ...       ...\n",
       "1095     3.0   NaN    0.0    7.6292\n",
       "1130     3.0  18.0    0.0    7.7750\n",
       "1294     3.0  28.5    0.0   16.1000\n",
       "860      3.0  26.0    0.0    7.9250\n",
       "1126     3.0  28.0    0.0    7.8958\n",
       "\n",
       "[981 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = ['pclass', 'age', 'parch', 'fare']\n",
    "\n",
    "X_train_num = X_train[num_cols]\n",
    "X_test_num = X_test[num_cols]\n",
    "X_train_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>QUESTIONS</b>:</p>\n",
    "    <ul>\n",
    "        <li>And now, what would happen if you tried to fit a <tt>RandomForestClassifier</tt>?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to look into a summary of the data that we try to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 981 entries, 1139 to 1126\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   pclass  981 non-null    float64\n",
      " 1   age     784 non-null    float64\n",
      " 2   parch   981 non-null    float64\n",
      " 3   fare    980 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 38.3 KB\n"
     ]
    }
   ],
   "source": [
    "X_train_num.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are some missing data, we can replace them with a mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 981 entries, 1139 to 1126\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   pclass  981 non-null    float64\n",
      " 1   age     981 non-null    float64\n",
      " 2   parch   981 non-null    float64\n",
      " 3   fare    981 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 38.3 KB\n"
     ]
    }
   ],
   "source": [
    "X_train_num_imputed = X_train_num.fillna(X_train_num.mean())\n",
    "X_train_num_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_num_imputed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>EXERCISE</b>:</p>\n",
    "    <ul>\n",
    "    <li>What should we do if there are also missing values in the test set?</li>\n",
    "    <li>Process the test set so as to be able to compute the test score of the model.</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "Solution is in `solutions/01-pandas_fillna_test.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass     2.298675\n",
       "age       29.347683\n",
       "parch      0.391437\n",
       "fare      33.686466\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "X_test_num_imputed = X_test_num.fillna(X_train_num.mean())\n",
    "model\n",
    "X_train_num.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Making it less error prone using scikit-learn <a class=\"anchor\" id=\"workingnumerical_errorprone\"></a> [↑](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn provides some \"transformers\" to preprocess the data. `sklearn.impute.SimpleImputer` is a transformer allowing for the same job than the processing done with Pandas. However, we will see later that it integrates greatly with other scikit-learn components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As any estimator in scikit-learn, a transformer has a `fit` method which should be called on the training data to learn the required statistics. In the case of a mean imputer, we need to compute the mean for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SimpleImputer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SimpleImputer()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.fit(X_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.29867482, 29.34768278,  0.39143731, 33.68646633])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To impute the values by the mean, we can use the `transform` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.    , 38.    ,  0.    ,  7.8958],\n",
       "       [ 3.    ,  6.    ,  1.    , 15.2458],\n",
       "       [ 1.    , 52.    ,  1.    , 79.65  ],\n",
       "       ...,\n",
       "       [ 3.    , 28.5   ,  0.    , 16.1   ],\n",
       "       [ 3.    , 26.    ,  0.    ,  7.925 ],\n",
       "       [ 3.    , 28.    ,  0.    ,  7.8958]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.transform(X_train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previoulsy mentioned, we should impute with the values computed in `fit` when imputing the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>What is a \"Transformer\"?</b>: <br/>\n",
    "\n",
    "A scikit-learn transform should implement at least these methods:\n",
    "\n",
    "<ul>\n",
    "    <li>fit(X, y=None)</li>\n",
    "    <li>transform(X)</li>\n",
    "    <li>get_params()</li>\n",
    "    <li>set_params(**kwargs)</li>  \n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'add_indicator': False,\n",
       " 'copy': True,\n",
       " 'fill_value': None,\n",
       " 'keep_empty_features': False,\n",
       " 'missing_values': nan,\n",
       " 'strategy': 'mean'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = imputer.get_params()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Fit the imputer on `X`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "    Input data, where `n_samples` is the number of samples and\n",
      "    `n_features` is the number of features.\n",
      "\n",
      "y : Ignored\n",
      "    Not used, present here for API consistency by convention.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "self : object\n",
      "    Fitted estimator.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.11/site-packages/sklearn/impute/_base.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "imputer.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Impute all missing values in `X`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      "    The input data to complete.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "X_imputed : {ndarray, sparse matrix} of shape                 (n_samples, n_features_out)\n",
      "    `X` with imputed values.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.11/site-packages/sklearn/impute/_base.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "imputer.transform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the attributes of our `imputer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['add_indicator',\n",
       " 'copy',\n",
       " 'feature_names_in_',\n",
       " 'fill_value',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'get_feature_names_out',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'indicator_',\n",
       " 'inverse_transform',\n",
       " 'keep_empty_features',\n",
       " 'missing_values',\n",
       " 'n_features_in_',\n",
       " 'set_output',\n",
       " 'set_params',\n",
       " 'statistics_',\n",
       " 'strategy',\n",
       " 'transform']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_attributes = [attr for attr in dir(imputer) if not attr.startswith('_')]\n",
    "public_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have among these attributes:\n",
    "\n",
    "- **parameters** (keys in get_params method output)\n",
    "- **methods** (fit, transform, etc.)\n",
    "- **estimated quantities** that appear after a `fit` (ending with `_`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fit',\n",
       " 'fit_transform',\n",
       " 'get_feature_names_out',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'inverse_transform',\n",
       " 'set_output',\n",
       " 'set_params',\n",
       " 'transform']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_methods = [\n",
    "    attr for attr in dir(imputer)\n",
    "    if not attr.startswith('_') and\n",
    "    not attr.endswith('_') and\n",
    "    attr not in params]\n",
    "public_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Convert the data back to the original representation.\n",
      "\n",
      "Inverts the `transform` operation performed on an array.\n",
      "This operation can only be performed after :class:`SimpleImputer` is\n",
      "instantiated with `add_indicator=True`.\n",
      "\n",
      "Note that `inverse_transform` can only invert the transform in\n",
      "features that have binary indicators for missing values. If a feature\n",
      "has no missing values at `fit` time, the feature won't have a binary\n",
      "indicator, and the imputation done at `transform` time won't be\n",
      "inverted.\n",
      "\n",
      ".. versionadded:: 0.24\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "X : array-like of shape                 (n_samples, n_features + n_features_missing_indicator)\n",
      "    The imputed data to be reverted to original data. It has to be\n",
      "    an augmented array of imputed data and the missing indicator mask.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "X_original : ndarray of shape (n_samples, n_features)\n",
      "    The original `X` with missing values as it was prior\n",
      "    to imputation.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.11/site-packages/sklearn/impute/_base.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "imputer.inverse_transform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated quantities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_names_in_', 'indicator_', 'n_features_in_', 'statistics_']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_attributes = [\n",
    "    attr for attr in dir(imputer)\n",
    "    if not attr.startswith('_') and\n",
    "    attr.endswith('_')]\n",
    "fit_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>EXERCISE</b>:</p>\n",
    "    <ul>\n",
    "        <li>What are the attributes of a RandomForestClassifier. You will decompose these in the 3 categories.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = model.get_params()\n",
    "params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apply',\n",
       " 'base_estimator',\n",
       " 'decision_path',\n",
       " 'estimator',\n",
       " 'estimator_params',\n",
       " 'fit',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'score',\n",
       " 'set_fit_request',\n",
       " 'set_params',\n",
       " 'set_score_request']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_methods = [\n",
    "    attr for attr in dir(RandomForestClassifier())\n",
    "    if not attr.startswith('_') and\n",
    "    not attr.endswith('_') and\n",
    "    attr not in params]\n",
    "rf_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_estimator_',\n",
       " 'classes_',\n",
       " 'estimator_',\n",
       " 'estimators_',\n",
       " 'feature_importances_',\n",
       " 'feature_names_in_',\n",
       " 'n_classes_',\n",
       " 'n_features_in_',\n",
       " 'n_outputs_']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_attributes = [\n",
    "    attr for attr in dir(model)\n",
    "    if not attr.startswith('_') and\n",
    "    attr.endswith('_')]\n",
    "fit_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenchenjunjie/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6676829268292683"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num_imputed = imputer.fit_transform(X_train_num)\n",
    "model.fit(X_train_num_imputed,y_train).score(X_test_num_imputed,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Pipeline\n",
    "\n",
    "We saw earlier that we should be careful when preprocessing data to avoid any \"data leak\" (i.e. reusing some knowledge from the training when testing our model). Scikit-learn provides the `Pipeline` class to make successive transformations. In addition, it will ensure that the right operations will be applied at the right time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;simpleimputer&#x27;, SimpleImputer()),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(n_estimators=200))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;simpleimputer&#x27;, SimpleImputer()),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(n_estimators=200))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('simpleimputer', SimpleImputer()),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(n_estimators=200))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(SimpleImputer(strategy='mean'),\n",
    "                      RandomForestClassifier(n_estimators=200))\n",
    "model.fit(X_train_num, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative syntax using named \"steps\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier(n_estimators=200))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier(n_estimators=200))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer()),\n",
       "                ('classifier', RandomForestClassifier(n_estimators=200))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy='mean')),\n",
    "    (\"classifier\", RandomForestClassifier(n_estimators=200))    \n",
    "])\n",
    "model.fit(X_train_num, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6707317073170732"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_num, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving your estimator in HTML for presentations, blog posts etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import estimator_html_repr\n",
    "\n",
    "with open('model.html', 'w') as fid:\n",
    "    fid.write(estimator_html_repr(model))\n",
    "\n",
    "# !open model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Pipeline steps\n",
    "\n",
    "A pipeline is a sequence of `steps`. Each `step` is a scikit-learn estimator. All steps except the last one are typically **transformers** (fit, fit_transform, transform methods) and the last step is a **classifier** or a **regressor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('imputer', SimpleImputer()),\n",
       " ('classifier', RandomForestClassifier(n_estimators=200))]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.steps  # accessing steps as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'imputer': SimpleImputer(),\n",
       " 'classifier': RandomForestClassifier(n_estimators=200)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps  # accessing steps with their names as a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer())])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[:1]  # slicing a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import is_classifier\n",
    "\n",
    "is_classifier(model[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's decompose the pipeline and chain the operations manually (mimicking what the Pipeline object does internally):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6676829268292683"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = model[0] # model[:-1]\n",
    "classifier = model[-1]\n",
    "\n",
    "X_train_preproc = preprocessor.fit_transform(X_train_num, y_train)\n",
    "X_test_preproc = preprocessor.transform(X_test_num)\n",
    "\n",
    "classifier.fit(X_train_preproc, y_train)\n",
    "classifier.score(X_test_preproc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Towards a ColumnTransformer\n",
    "\n",
    "If we want to directly fit the model on `X_train`, we can select the numerical columns using  a `ColumnTransformer` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mColumnTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtransformers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mremainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'drop'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msparse_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtransformer_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose_feature_names_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Applies transformers to columns of an array or pandas DataFrame.\n",
      "\n",
      "This estimator allows different columns or column subsets of the input\n",
      "to be transformed separately and the features generated by each transformer\n",
      "will be concatenated to form a single feature space.\n",
      "This is useful for heterogeneous or columnar data, to combine several\n",
      "feature extraction mechanisms or transformations into a single transformer.\n",
      "\n",
      "Read more in the :ref:`User Guide <column_transformer>`.\n",
      "\n",
      ".. versionadded:: 0.20\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "transformers : list of tuples\n",
      "    List of (name, transformer, columns) tuples specifying the\n",
      "    transformer objects to be applied to subsets of the data.\n",
      "\n",
      "    name : str\n",
      "        Like in Pipeline and FeatureUnion, this allows the transformer and\n",
      "        its parameters to be set using ``set_params`` and searched in grid\n",
      "        search.\n",
      "    transformer : {'drop', 'passthrough'} or estimator\n",
      "        Estimator must support :term:`fit` and :term:`transform`.\n",
      "        Special-cased strings 'drop' and 'passthrough' are accepted as\n",
      "        well, to indicate to drop the columns or to pass them through\n",
      "        untransformed, respectively.\n",
      "    columns :  str, array-like of str, int, array-like of int,                 array-like of bool, slice or callable\n",
      "        Indexes the data on its second axis. Integers are interpreted as\n",
      "        positional columns, while strings can reference DataFrame columns\n",
      "        by name.  A scalar string or int should be used where\n",
      "        ``transformer`` expects X to be a 1d array-like (vector),\n",
      "        otherwise a 2d array will be passed to the transformer.\n",
      "        A callable is passed the input data `X` and can return any of the\n",
      "        above. To select multiple columns by name or dtype, you can use\n",
      "        :obj:`make_column_selector`.\n",
      "\n",
      "remainder : {'drop', 'passthrough'} or estimator, default='drop'\n",
      "    By default, only the specified columns in `transformers` are\n",
      "    transformed and combined in the output, and the non-specified\n",
      "    columns are dropped. (default of ``'drop'``).\n",
      "    By specifying ``remainder='passthrough'``, all remaining columns that\n",
      "    were not specified in `transformers`, but present in the data passed\n",
      "    to `fit` will be automatically passed through. This subset of columns\n",
      "    is concatenated with the output of the transformers. For dataframes,\n",
      "    extra columns not seen during `fit` will be excluded from the output\n",
      "    of `transform`.\n",
      "    By setting ``remainder`` to be an estimator, the remaining\n",
      "    non-specified columns will use the ``remainder`` estimator. The\n",
      "    estimator must support :term:`fit` and :term:`transform`.\n",
      "    Note that using this feature requires that the DataFrame columns\n",
      "    input at :term:`fit` and :term:`transform` have identical order.\n",
      "\n",
      "sparse_threshold : float, default=0.3\n",
      "    If the output of the different transformers contains sparse matrices,\n",
      "    these will be stacked as a sparse matrix if the overall density is\n",
      "    lower than this value. Use ``sparse_threshold=0`` to always return\n",
      "    dense.  When the transformed output consists of all dense data, the\n",
      "    stacked result will be dense, and this keyword will be ignored.\n",
      "\n",
      "n_jobs : int, default=None\n",
      "    Number of jobs to run in parallel.\n",
      "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "    for more details.\n",
      "\n",
      "transformer_weights : dict, default=None\n",
      "    Multiplicative weights for features per transformer. The output of the\n",
      "    transformer is multiplied by these weights. Keys are transformer names,\n",
      "    values the weights.\n",
      "\n",
      "verbose : bool, default=False\n",
      "    If True, the time elapsed while fitting each transformer will be\n",
      "    printed as it is completed.\n",
      "\n",
      "verbose_feature_names_out : bool, default=True\n",
      "    If True, :meth:`get_feature_names_out` will prefix all feature names\n",
      "    with the name of the transformer that generated that feature.\n",
      "    If False, :meth:`get_feature_names_out` will not prefix any feature\n",
      "    names and will error if feature names are not unique.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "transformers_ : list\n",
      "    The collection of fitted transformers as tuples of\n",
      "    (name, fitted_transformer, column). `fitted_transformer` can be an\n",
      "    estimator, 'drop', or 'passthrough'. In case there were no columns\n",
      "    selected, this will be the unfitted transformer.\n",
      "    If there are remaining columns, the final element is a tuple of the\n",
      "    form:\n",
      "    ('remainder', transformer, remaining_columns) corresponding to the\n",
      "    ``remainder`` parameter. If there are remaining columns, then\n",
      "    ``len(transformers_)==len(transformers)+1``, otherwise\n",
      "    ``len(transformers_)==len(transformers)``.\n",
      "\n",
      "named_transformers_ : :class:`~sklearn.utils.Bunch`\n",
      "    Read-only attribute to access any transformer by given name.\n",
      "    Keys are transformer names and values are the fitted transformer\n",
      "    objects.\n",
      "\n",
      "sparse_output_ : bool\n",
      "    Boolean flag indicating whether the output of ``transform`` is a\n",
      "    sparse matrix or a dense numpy array, which depends on the output\n",
      "    of the individual transformers and the `sparse_threshold` keyword.\n",
      "\n",
      "output_indices_ : dict\n",
      "    A dictionary from each transformer name to a slice, where the slice\n",
      "    corresponds to indices in the transformed output. This is useful to\n",
      "    inspect which transformer is responsible for which transformed\n",
      "    feature(s).\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`. Only defined if the\n",
      "    underlying transformers expose such an attribute when fit.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "See Also\n",
      "--------\n",
      "make_column_transformer : Convenience function for\n",
      "    combining the outputs of multiple transformer objects applied to\n",
      "    column subsets of the original feature space.\n",
      "make_column_selector : Convenience function for selecting\n",
      "    columns based on datatype or the columns name with a regex pattern.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The order of the columns in the transformed feature matrix follows the\n",
      "order of how the columns are specified in the `transformers` list.\n",
      "Columns of the original feature matrix that are not specified are\n",
      "dropped from the resulting transformed feature matrix, unless specified\n",
      "in the `passthrough` keyword. Those columns specified with `passthrough`\n",
      "are added at the right to the output of the transformers.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import numpy as np\n",
      ">>> from sklearn.compose import ColumnTransformer\n",
      ">>> from sklearn.preprocessing import Normalizer\n",
      ">>> ct = ColumnTransformer(\n",
      "...     [(\"norm1\", Normalizer(norm='l1'), [0, 1]),\n",
      "...      (\"norm2\", Normalizer(norm='l1'), slice(2, 4))])\n",
      ">>> X = np.array([[0., 1., 2., 2.],\n",
      "...               [1., 1., 0., 1.]])\n",
      ">>> # Normalizer scales each row of X to unit norm. A separate scaling\n",
      ">>> # is applied for the two first and two last elements of each\n",
      ">>> # row independently.\n",
      ">>> ct.fit_transform(X)\n",
      "array([[0. , 1. , 0.5, 0.5],\n",
      "       [0.5, 0.5, 0. , 1. ]])\n",
      "\n",
      ":class:`ColumnTransformer` can be configured with a transformer that requires\n",
      "a 1d array by setting the column to a string:\n",
      "\n",
      ">>> from sklearn.feature_extraction import FeatureHasher\n",
      ">>> from sklearn.preprocessing import MinMaxScaler\n",
      ">>> import pandas as pd   # doctest: +SKIP\n",
      ">>> X = pd.DataFrame({\n",
      "...     \"documents\": [\"First item\", \"second one here\", \"Is this the last?\"],\n",
      "...     \"width\": [3, 4, 5],\n",
      "... })  # doctest: +SKIP\n",
      ">>> # \"documents\" is a string which configures ColumnTransformer to\n",
      ">>> # pass the documents column as a 1d array to the FeatureHasher\n",
      ">>> ct = ColumnTransformer(\n",
      "...     [(\"text_preprocess\", FeatureHasher(input_type=\"string\"), \"documents\"),\n",
      "...      (\"num_preprocess\", MinMaxScaler(), [\"width\"])])\n",
      ">>> X_trans = ct.fit_transform(X)  # doctest: +SKIP\n",
      "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ColumnTransformer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;numerical preproc.&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;imputer&#x27;, SimpleImputer(),\n",
       "                                                  [&#x27;pclass&#x27;, &#x27;age&#x27;]),\n",
       "                                                 (&#x27;imputer2&#x27;, SimpleImputer(),\n",
       "                                                  [&#x27;parch&#x27;, &#x27;fare&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;numerical preproc.&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;imputer&#x27;, SimpleImputer(),\n",
       "                                                  [&#x27;pclass&#x27;, &#x27;age&#x27;]),\n",
       "                                                 (&#x27;imputer2&#x27;, SimpleImputer(),\n",
       "                                                  [&#x27;parch&#x27;, &#x27;fare&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical preproc.: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;imputer&#x27;, SimpleImputer(), [&#x27;pclass&#x27;, &#x27;age&#x27;]),\n",
       "                                (&#x27;imputer2&#x27;, SimpleImputer(),\n",
       "                                 [&#x27;parch&#x27;, &#x27;fare&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">imputer</label><div class=\"sk-toggleable__content\"><pre>[&#x27;pclass&#x27;, &#x27;age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">imputer2</label><div class=\"sk-toggleable__content\"><pre>[&#x27;parch&#x27;, &#x27;fare&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('numerical preproc.',\n",
       "                 ColumnTransformer(transformers=[('imputer', SimpleImputer(),\n",
       "                                                  ['pclass', 'age']),\n",
       "                                                 ('imputer2', SimpleImputer(),\n",
       "                                                  ['parch', 'fare'])])),\n",
       "                ('classifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_preprocessing = ColumnTransformer([\n",
    "    (\"imputer\", SimpleImputer(strategy='mean'), num_cols[:2]),\n",
    "    (\"imputer2\", SimpleImputer(strategy='mean'), num_cols[2:])\n",
    "])\n",
    "    \n",
    "model = Pipeline([\n",
    "    (\"numerical preproc.\", numerical_preprocessing),\n",
    "    (\"classifier\", RandomForestClassifier(n_estimators=100)),\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.676829268292683"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Working only with categorical data <a class=\"anchor\" id=\"workingcategorical\"></a> [↑](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical columns (even more string data types) are not supported natively by machine-learning algorithms and required some preprocessing step usually called encoding. The most classical categorical encoders are the `OrdinalEncoder` and the `OneHotEncoder`. Let's first see the `OrdinalEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Rekic, Mr. Tido</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349249</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Boulos, Master. Akar</td>\n",
       "      <td>male</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2678</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Syria Kent, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Taussig, Mr. Emil</td>\n",
       "      <td>male</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110413</td>\n",
       "      <td>79.6500</td>\n",
       "      <td>E67</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Straus, Mr. Isidor</td>\n",
       "      <td>male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17483</td>\n",
       "      <td>221.7792</td>\n",
       "      <td>C55 C57</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Rosblom, Mr. Viktor Richard</td>\n",
       "      <td>male</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>370129</td>\n",
       "      <td>20.2125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass                         name   sex  ...  boat  body       home.dest\n",
       "1139     3.0              Rekic, Mr. Tido  male  ...   NaN   NaN             NaN\n",
       "678      3.0         Boulos, Master. Akar  male  ...   NaN   NaN  Syria Kent, ON\n",
       "290      1.0            Taussig, Mr. Emil  male  ...   NaN   NaN    New York, NY\n",
       "285      1.0           Straus, Mr. Isidor  male  ...   NaN  96.0    New York, NY\n",
       "1157     3.0  Rosblom, Mr. Viktor Richard  male  ...   NaN   NaN             NaN\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['sex', 'embarked', 'pclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat = X_train[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 981 entries, 1139 to 1126\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   sex       981 non-null    category\n",
      " 1   embarked  980 non-null    category\n",
      " 2   pclass    981 non-null    float64 \n",
      "dtypes: category(2), float64(1)\n",
      "memory usage: 17.5 KB\n"
     ]
    }
   ],
   "source": [
    "#  X_train_cat.isna().sum()\n",
    "X_train_cat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;categorical_preproc&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical_preproc&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;ordinal_encoder&#x27;,\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  [&#x27;sex&#x27;, &#x27;embarked&#x27;,\n",
       "                                                   &#x27;pclass&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;categorical_preproc&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical_preproc&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;ordinal_encoder&#x27;,\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  [&#x27;sex&#x27;, &#x27;embarked&#x27;,\n",
       "                                                   &#x27;pclass&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_preproc: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;categorical_preproc&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;ordinal_encoder&#x27;,\n",
       "                                                  OrdinalEncoder())]),\n",
       "                                 [&#x27;sex&#x27;, &#x27;embarked&#x27;, &#x27;pclass&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_preproc</label><div class=\"sk-toggleable__content\"><pre>[&#x27;sex&#x27;, &#x27;embarked&#x27;, &#x27;pclass&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('categorical_preproc',\n",
       "                 ColumnTransformer(transformers=[('categorical_preproc',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('ordinal_encoder',\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  ['sex', 'embarked',\n",
       "                                                   'pclass'])])),\n",
       "                ('classifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    (\"ordinal_encoder\", OrdinalEncoder())\n",
    "])\n",
    "\n",
    "categorical_preprocessing = ColumnTransformer([\n",
    "    (\"categorical_preproc\", cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"categorical_preproc\", categorical_preprocessing),\n",
    "    (\"classifier\", RandomForestClassifier(n_estimators=100))\n",
    "])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7713414634146342"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing and updating parameters of a Pipeline\n",
    "\n",
    "Pipeline is yet another scikit-learn estimators. It therefore has the methods `set_params` and `get_params`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('categorical_preproc',\n",
       "   ColumnTransformer(transformers=[('categorical_preproc',\n",
       "                                    Pipeline(steps=[('imputer',\n",
       "                                                     SimpleImputer(fill_value='missing',\n",
       "                                                                   strategy='constant')),\n",
       "                                                    ('ordinal_encoder',\n",
       "                                                     OrdinalEncoder())]),\n",
       "                                    ['sex', 'embarked', 'pclass'])])),\n",
       "  ('classifier', RandomForestClassifier())],\n",
       " 'verbose': False,\n",
       " 'categorical_preproc': ColumnTransformer(transformers=[('categorical_preproc',\n",
       "                                  Pipeline(steps=[('imputer',\n",
       "                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                 strategy='constant')),\n",
       "                                                  ('ordinal_encoder',\n",
       "                                                   OrdinalEncoder())]),\n",
       "                                  ['sex', 'embarked', 'pclass'])]),\n",
       " 'classifier': RandomForestClassifier(),\n",
       " 'categorical_preproc__n_jobs': None,\n",
       " 'categorical_preproc__remainder': 'drop',\n",
       " 'categorical_preproc__sparse_threshold': 0.3,\n",
       " 'categorical_preproc__transformer_weights': None,\n",
       " 'categorical_preproc__transformers': [('categorical_preproc',\n",
       "   Pipeline(steps=[('imputer',\n",
       "                    SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "                   ('ordinal_encoder', OrdinalEncoder())]),\n",
       "   ['sex', 'embarked', 'pclass'])],\n",
       " 'categorical_preproc__verbose': False,\n",
       " 'categorical_preproc__verbose_feature_names_out': True,\n",
       " 'categorical_preproc__categorical_preproc': Pipeline(steps=[('imputer',\n",
       "                  SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "                 ('ordinal_encoder', OrdinalEncoder())]),\n",
       " 'categorical_preproc__categorical_preproc__memory': None,\n",
       " 'categorical_preproc__categorical_preproc__steps': [('imputer',\n",
       "   SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "  ('ordinal_encoder', OrdinalEncoder())],\n",
       " 'categorical_preproc__categorical_preproc__verbose': False,\n",
       " 'categorical_preproc__categorical_preproc__imputer': SimpleImputer(fill_value='missing', strategy='constant'),\n",
       " 'categorical_preproc__categorical_preproc__ordinal_encoder': OrdinalEncoder(),\n",
       " 'categorical_preproc__categorical_preproc__imputer__add_indicator': False,\n",
       " 'categorical_preproc__categorical_preproc__imputer__copy': True,\n",
       " 'categorical_preproc__categorical_preproc__imputer__fill_value': 'missing',\n",
       " 'categorical_preproc__categorical_preproc__imputer__keep_empty_features': False,\n",
       " 'categorical_preproc__categorical_preproc__imputer__missing_values': nan,\n",
       " 'categorical_preproc__categorical_preproc__imputer__strategy': 'constant',\n",
       " 'categorical_preproc__categorical_preproc__ordinal_encoder__categories': 'auto',\n",
       " 'categorical_preproc__categorical_preproc__ordinal_encoder__dtype': numpy.float64,\n",
       " 'categorical_preproc__categorical_preproc__ordinal_encoder__encoded_missing_value': nan,\n",
       " 'categorical_preproc__categorical_preproc__ordinal_encoder__handle_unknown': 'error',\n",
       " 'categorical_preproc__categorical_preproc__ordinal_encoder__max_categories': None,\n",
       " 'categorical_preproc__categorical_preproc__ordinal_encoder__min_frequency': None,\n",
       " 'categorical_preproc__categorical_preproc__ordinal_encoder__unknown_value': None,\n",
       " 'classifier__bootstrap': True,\n",
       " 'classifier__ccp_alpha': 0.0,\n",
       " 'classifier__class_weight': None,\n",
       " 'classifier__criterion': 'gini',\n",
       " 'classifier__max_depth': None,\n",
       " 'classifier__max_features': 'sqrt',\n",
       " 'classifier__max_leaf_nodes': None,\n",
       " 'classifier__max_samples': None,\n",
       " 'classifier__min_impurity_decrease': 0.0,\n",
       " 'classifier__min_samples_leaf': 1,\n",
       " 'classifier__min_samples_split': 2,\n",
       " 'classifier__min_weight_fraction_leaf': 0.0,\n",
       " 'classifier__n_estimators': 100,\n",
       " 'classifier__n_jobs': None,\n",
       " 'classifier__oob_score': False,\n",
       " 'classifier__random_state': None,\n",
       " 'classifier__verbose': 0,\n",
       " 'classifier__warm_start': False}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('categorical_preproc',\n",
       "   ColumnTransformer(transformers=[('categorical_preproc',\n",
       "                                    Pipeline(steps=[('imputer',\n",
       "                                                     SimpleImputer(fill_value='missing',\n",
       "                                                                   strategy='constant')),\n",
       "                                                    ('ordinal_encoder',\n",
       "                                                     OrdinalEncoder())]),\n",
       "                                    ['sex', 'embarked', 'pclass'])])),\n",
       "  ('classifier', RandomForestClassifier(n_estimators=666))],\n",
       " 'verbose': False,\n",
       " 'categorical_preproc': ColumnTransformer(transformers=[('categorical_preproc',\n",
       "                                  Pipeline(steps=[('imputer',\n",
       "                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                 strategy='constant')),\n",
       "                                                  ('ordinal_encoder',\n",
       "                                                   OrdinalEncoder())]),\n",
       "                                  ['sex', 'embarked', 'pclass'])]),\n",
       " 'classifier': RandomForestClassifier(n_estimators=666),\n",
       " 'categorical_preproc__n_jobs': None,\n",
       " 'categorical_preproc__remainder': 'drop',\n",
       " 'categorical_preproc__sparse_threshold': 0.3,\n",
       " 'categorical_preproc__transformer_weights': None,\n",
       " 'categorical_preproc__transformers': [('categorical_preproc',\n",
       "   Pipeline(steps=[('imputer',\n",
       "                    SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "                   ('ordinal_encoder', OrdinalEncoder())]),\n",
       "   ['sex', 'embarked', 'pclass'])],\n",
       " 'categorical_preproc__verbose': False,\n",
       " 'categorical_preproc__verbose_feature_names_out': True,\n",
       " 'categorical_preproc__categorical_preproc': Pipeline(steps=[('imputer',\n",
       "                  SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "                 ('ordinal_encoder', OrdinalEncoder())]),\n",
       " 'categorical_preproc__categorical_preproc__memory': None,\n",
       " 'categorical_preproc__categorical_preproc__steps': [('imputer',\n",
       "   SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "  ('ordinal_encoder', OrdinalEncoder())],\n",
       " 'categorical_preproc__categorical_preproc__verbose': False,\n",
       " 'categorical_preproc__categorical_preproc__imputer': SimpleImputer(fill_value='missing', strategy='constant'),\n",
       " 'categorical_preproc__categorical_preproc__ordinal_encoder': OrdinalEncoder(),\n",
       " 'categorical_preproc__categorical_preproc__imputer__add_indicator': False,\n",
       " 'categorical_preproc__categorical_preproc__imputer__copy': True,\n",
       " 'categorical_preproc__categorical_preproc__imputer__fill_value': 'missing',\n",
       " 'categorical_preproc__categorical_preproc__imputer__keep_empty_features': False,\n",
       " 'categorical_preproc__categorical_preproc__imputer__missing_values': nan,\n",
       " 'categorical_preproc__categorical_preproc__imputer__strategy': 'constant',\n",
       " 'categorical_preproc__categorical_preproc__ordinal_encoder__categories': 'auto',\n",
       " 'categorical_preproc__categorical_preproc__ordinal_encoder__dtype': numpy.float64,\n",
       " 'categorical_preproc__categorical_preproc__ordinal_encoder__encoded_missing_value': nan,\n",
       " 'categorical_preproc__categorical_preproc__ordinal_encoder__handle_unknown': 'error',\n",
       " 'categorical_preproc__categorical_preproc__ordinal_encoder__max_categories': None,\n",
       " 'categorical_preproc__categorical_preproc__ordinal_encoder__min_frequency': None,\n",
       " 'categorical_preproc__categorical_preproc__ordinal_encoder__unknown_value': None,\n",
       " 'classifier__bootstrap': True,\n",
       " 'classifier__ccp_alpha': 0.0,\n",
       " 'classifier__class_weight': None,\n",
       " 'classifier__criterion': 'gini',\n",
       " 'classifier__max_depth': None,\n",
       " 'classifier__max_features': 'sqrt',\n",
       " 'classifier__max_leaf_nodes': None,\n",
       " 'classifier__max_samples': None,\n",
       " 'classifier__min_impurity_decrease': 0.0,\n",
       " 'classifier__min_samples_leaf': 1,\n",
       " 'classifier__min_samples_split': 2,\n",
       " 'classifier__min_weight_fraction_leaf': 0.0,\n",
       " 'classifier__n_estimators': 666,\n",
       " 'classifier__n_jobs': None,\n",
       " 'classifier__oob_score': False,\n",
       " 'classifier__random_state': None,\n",
       " 'classifier__verbose': 0,\n",
       " 'classifier__warm_start': False}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_params(classifier__n_estimators=666)\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>EXERCISE</b>:</p>\n",
    "    There are many other types of ways to encode categorical variables.\n",
    "    <ul>\n",
    "        <li>Write your own categorical encoder CountEncoder. The idea is to replace categorical variables with their count in the train set.</li>\n",
    "        <li>Change the ordinal encoder in the pipeline above with an instance of your CountEncoder.</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "Your class will need to inherit from `BaseEstimator`, `TransformerMixin` in `sklearn.base` submodule.\n",
    "You will use the class `Counter` from the collections module in the standard library.\n",
    "\n",
    "You will your code on this toy example\n",
    "\n",
    "```python\n",
    ">>> X = np.array([\n",
    "...    [0, 2],\n",
    "...    [1, 3],\n",
    "...    [1, 1],\n",
    "...    [1, 1],\n",
    "... ])\n",
    ">>> ce = CountEncoder()\n",
    ">>> print(ce.fit_transform(X))\n",
    "[[1 1]\n",
    " [3 1]\n",
    " [3 2]\n",
    " [3 2]]\n",
    "```\n",
    "\n",
    "Solution is in `solutions/01-count_encoder.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Dict subclass for counting hashable items.  Sometimes called a bag\n",
      "or multiset.  Elements are stored as dictionary keys and their counts\n",
      "are stored as dictionary values.\n",
      "\n",
      ">>> c = Counter('abcdeabcdabcaba')  # count elements from a string\n",
      "\n",
      ">>> c.most_common(3)                # three most common elements\n",
      "[('a', 5), ('b', 4), ('c', 3)]\n",
      ">>> sorted(c)                       # list all unique elements\n",
      "['a', 'b', 'c', 'd', 'e']\n",
      ">>> ''.join(sorted(c.elements()))   # list elements with repetitions\n",
      "'aaaaabbbbcccdde'\n",
      ">>> sum(c.values())                 # total of all counts\n",
      "15\n",
      "\n",
      ">>> c['a']                          # count of letter 'a'\n",
      "5\n",
      ">>> for elem in 'shazam':           # update counts from an iterable\n",
      "...     c[elem] += 1                # by adding 1 to each element's count\n",
      ">>> c['a']                          # now there are seven 'a'\n",
      "7\n",
      ">>> del c['b']                      # remove all 'b'\n",
      ">>> c['b']                          # now there are zero 'b'\n",
      "0\n",
      "\n",
      ">>> d = Counter('simsalabim')       # make another counter\n",
      ">>> c.update(d)                     # add in the second counter\n",
      ">>> c['a']                          # now there are nine 'a'\n",
      "9\n",
      "\n",
      ">>> c.clear()                       # empty the counter\n",
      ">>> c\n",
      "Counter()\n",
      "\n",
      "Note:  If a count is set to zero or reduced to zero, it will remain\n",
      "in the counter until the entry is deleted or the counter is cleared:\n",
      "\n",
      ">>> c = Counter('aaabbc')\n",
      ">>> c['b'] -= 2                     # reduce the count of 'b' by two\n",
      ">>> c.most_common()                 # 'b' is still in, but its count is zero\n",
      "[('a', 3), ('c', 1), ('b', 0)]\n",
      "\u001b[0;31mInit docstring:\u001b[0m\n",
      "Create a new, empty Counter object.  And if given, count elements\n",
      "from an input iterable.  Or, initialize the count from another mapping\n",
      "of elements to their counts.\n",
      "\n",
      ">>> c = Counter()                           # a new, empty counter\n",
      ">>> c = Counter('gallahad')                 # a new counter from an iterable\n",
      ">>> c = Counter({'a': 4, 'b': 2})           # a new counter from a mapping\n",
      ">>> c = Counter(a=4, b=2)                   # a new counter from keyword args\n",
      "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.11/collections/__init__.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     _NaNCounter"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2],\n",
       "       [1, 3],\n",
       "       [1, 1],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([\n",
    "    [0, 2],\n",
    "    [1, 3],\n",
    "    [1, 1],\n",
    "    [1, 1],\n",
    "])\n",
    "Counter(X[:,1])\n",
    "check_array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Combining both categorical and numerical data in the pipeline <a class=\"anchor\" id=\"combining\"></a> [↑](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>EXERCISE</b>:</p>\n",
    "    <ul>\n",
    "    <li>Try to combine the numerical and categorical pipelines into a single <tt>ColumnTransformer</tt></li>\n",
    "        <li>Fit a <tt>RandomForestClassifier</tt> on the output of this feature engineering. How does the test score evolve?</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "Solution is in `solutions/01b-full_column_transformer.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'male'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb Cellule 87\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y145sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m categorical_preprocessing \u001b[39m=\u001b[39m ColumnTransformer([\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y145sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mcategorical_preproc\u001b[39m\u001b[39m\"\u001b[39m, cat_pipeline, cat_cols)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y145sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m ])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y145sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model \u001b[39m=\u001b[39m Pipeline([\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y145sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mcategorical_preproc\u001b[39m\u001b[39m\"\u001b[39m, categorical_preprocessing),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y145sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m\"\u001b[39m, RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y145sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m ])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y145sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y145sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m model\u001b[39m.\u001b[39mscore(X_test, y_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:416\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \n\u001b[1;32m    392\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    415\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 416\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps)\n\u001b[1;32m    417\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[1;32m    418\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    368\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    369\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    371\u001b[0m     cloned_transformer,\n\u001b[1;32m    372\u001b[0m     X,\n\u001b[1;32m    373\u001b[0m     y,\n\u001b[1;32m    374\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    375\u001b[0m     message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    376\u001b[0m     message\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(step_idx),\n\u001b[1;32m    377\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps[name],\n\u001b[1;32m    378\u001b[0m )\n\u001b[1;32m    379\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:950\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    949\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 950\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    951\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:743\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_column_callables(X)\n\u001b[1;32m    741\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m--> 743\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n\u001b[1;32m    745\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result:\n\u001b[1;32m    746\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:670\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    664\u001b[0m transformers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m    665\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(\n\u001b[1;32m    666\u001b[0m         fitted\u001b[39m=\u001b[39mfitted, replace_strings\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, column_as_strings\u001b[39m=\u001b[39mcolumn_as_strings\n\u001b[1;32m    667\u001b[0m     )\n\u001b[1;32m    668\u001b[0m )\n\u001b[1;32m    669\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m     \u001b[39mreturn\u001b[39;00m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)(\n\u001b[1;32m    671\u001b[0m         delayed(func)(\n\u001b[1;32m    672\u001b[0m             transformer\u001b[39m=\u001b[39mclone(trans) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted \u001b[39melse\u001b[39;00m trans,\n\u001b[1;32m    673\u001b[0m             X\u001b[39m=\u001b[39m_safe_indexing(X, column, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m    674\u001b[0m             y\u001b[39m=\u001b[39my,\n\u001b[1;32m    675\u001b[0m             weight\u001b[39m=\u001b[39mweight,\n\u001b[1;32m    676\u001b[0m             message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumnTransformer\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    677\u001b[0m             message\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(name, idx, \u001b[39mlen\u001b[39m(transformers)),\n\u001b[1;32m    678\u001b[0m         )\n\u001b[1;32m    679\u001b[0m         \u001b[39mfor\u001b[39;00m idx, (name, trans, column, weight) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(transformers, \u001b[39m1\u001b[39m)\n\u001b[1;32m    680\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    682\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mapply_async(batch, callback\u001b[39m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:950\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    949\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 950\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    951\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:472\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    470\u001b[0m fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m    471\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(last_step, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 472\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39mfit_transform(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[1;32m    473\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    474\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\u001b[39m.\u001b[39mtransform(Xt)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "\u001b[1;32m/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb Cellule 87\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y145sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y145sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     X \u001b[39m=\u001b[39m check_array(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y145sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y145sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcounters_ \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y145sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         Counter(X[:, i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y145sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    916\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype, xp\u001b[39m=\u001b[39mxp)\n\u001b[1;32m    918\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    919\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    920\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    921\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39masarray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    382\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'male'"
     ]
    }
   ],
   "source": [
    "# Let's put this now in a Pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    (\"count_encoder\", CountEncoder())\n",
    "])\n",
    "\n",
    "categorical_preprocessing = ColumnTransformer([\n",
    "    (\"categorical_preproc\", cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"categorical_preproc\", categorical_preprocessing),\n",
    "    (\"classifier\", RandomForestClassifier(n_estimators=100))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [3 1]\n",
      " [3 2]\n",
      " [3 2]\n",
      " [0 2]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "dtype='numeric' is not compatible with arrays of bytes/strings.Convert your data to numeric values explicitly instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb Cellule 88\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y215sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# [[1 1]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y215sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m#  [3 1]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y215sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m#  [3 2]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y215sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m#  [3 2]]  \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y215sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m a\u001b[39m=\u001b[39m[[\u001b[39m\"\u001b[39m\u001b[39m123\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y215sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m X \u001b[39m=\u001b[39m check_array(a)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenchenjunjie/M1_saclay/datacamp/datacamp-master/02_pipelines_and_column_transformers/01-sklearn_API_pipeline_columntransformer.ipynb#Y215sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m X\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:948\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    941\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    943\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    944\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    945\u001b[0m         )\n\u001b[1;32m    947\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array\u001b[39m.\u001b[39mdtype, \u001b[39m\"\u001b[39m\u001b[39mkind\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 948\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    949\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    950\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    951\u001b[0m     )\n\u001b[1;32m    952\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    953\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: dtype='numeric' is not compatible with arrays of bytes/strings.Convert your data to numeric values explicitly instead."
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.base import check_array\n",
    "from sklearn.base import check_is_fitted\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CountEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        X = check_array(X)\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        self.counters_ = [\n",
    "            Counter(X[:, i]) for i in range(self.n_features_in_)\n",
    "        ]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "        X_t = np.zeros_like(X, dtype=int)\n",
    "        for i, counter in enumerate(self.counters_):\n",
    "            for k, v in counter.items():\n",
    "                X_t[X[:, i] == k, i] = v\n",
    "        return X_t\n",
    "    \n",
    "X = np.array([\n",
    "    [0, 2],\n",
    "    [1, 3],\n",
    "    [1, 1],\n",
    "    [1, 1],\n",
    "])\n",
    "ce = CountEncoder()\n",
    "print(ce.fit(X).transform(np.r_[X, [[2, 1]]]))\n",
    "# [[1 1]\n",
    "#  [3 1]\n",
    "#  [3 2]\n",
    "#  [3 2]]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7926829268292683"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    (\"ordinal_encoder\", OrdinalEncoder())\n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    (\"imputer\", SimpleImputer(strategy='mean'), num_cols),\n",
    "    (\"categorical_preproc\", cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"preproc\", preprocessing),\n",
    "    (\"classifier\", RandomForestClassifier(n_estimators=100))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 From one split to cross-validation <a class=\"anchor\" id=\"crossvalidation\"></a> [↑](#Table-of-contents)\n",
    "\n",
    "CV objects are parametrized to split data in multiple train/test splits.\n",
    "\n",
    "A splitter should implement a `split` method.\n",
    "\n",
    "Given a `model`, some data `X, y` and a splitter one can fit and score on\n",
    "all requested data splits. Functions to do this are `cross_val_score`\n",
    "(historical way) and `cross_validate` (more modern way).\n",
    "\n",
    "Let's first define a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenchenjunjie/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:227: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.975609756097561"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skrub import TableVectorizer\n",
    "\n",
    "\n",
    "model = make_pipeline(TableVectorizer(numerical_transformer=SimpleImputer()), RandomForestClassifier())\n",
    "model.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ordinal_encoder\", OrdinalEncoder())\n",
    "])\n",
    "\n",
    "categorical_preprocessing = ColumnTransformer([\n",
    "    (\"categorical_preproc\", cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"categorical_preproc\", categorical_preprocessing),\n",
    "    (\"classifier\", RandomForestClassifier(n_estimators=100))\n",
    "])\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use a default 5-fold CV. You will see that there is a large amount of discrepancy among the test_score values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_results = cross_validate(model, X_df, y, cv=5)\n",
    "pd.DataFrame(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_results).agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason is that default CV object (here 5-fold CV) is deterministic, while the distribution of \"survivor\" is not uniform in the dataset. See:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.astype(int).to_frame().groupby(y.index.values // 100).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this one needs stratified folds (so that the fraction of \"survivors\" is the same in each fold) but also to shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = cross_validate(model, X_df, y, cv=cv)\n",
    "pd.DataFrame(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_results).agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance across folds is now much smaller which is great!\n",
    "\n",
    "Let's look at the cross-validation scheme with a pretty plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_utils import plot_cv_indices\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(9, 4))\n",
    "\n",
    "for shuffle, ax in zip([False, True], axes):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=shuffle)\n",
    "    plot_cv_indices(cv, X_df, y, ax=ax)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html for more details and a list of the different CV objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing your own cross-validation object\n",
    "\n",
    "A splitter should implement the `split` and `get_n_splits` method. The `split` should return an iterable of tuples of indices and `get_n_splits` an integer corresponding to the number of splits/folds. If you know about `yield` and Python generators you can use these.\n",
    "\n",
    "Let's first see what we get with the `cv` object above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.get_n_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_idx, test_idx in cv.split(X_df, y):\n",
    "    print(train_idx[:5], test_idx[:5])\n",
    "    print(f\"N. samples train: {len(train_idx)}  -- N. samples test: {len(test_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>EXERCISE</b>:</p>\n",
    "    <ul>\n",
    "        <li>Imagine that the index of <code>y</code> gives you some provenance about the sample (e.g. which cohort of subjects in a clinical study). Write a splitter that allows to test the performance of a model on a left-out cohort. In other words, you will do as many splits as the number of unique values in <code>y.index.values</code>, and predict of each left-out cohort. To simulate this, we will modify the index variable <code>y</code>, just for educational purposes.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "Solution is in `solutions/01c-splitter.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_with_provenance = y.copy()\n",
    "y_with_provenance.index = y_with_provenance.index.values // 200  # to easily mimic 5 cohorts\n",
    "n_splits = y_with_provenance.index.nunique()\n",
    "print(n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When you're done with this notebook you can do the assignments on scikit-learn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
